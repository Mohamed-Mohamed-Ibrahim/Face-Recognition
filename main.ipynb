{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":847361,"sourceType":"datasetVersion","datasetId":244146}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **import Libraries**","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.229926Z","iopub.execute_input":"2025-04-29T13:44:05.230979Z","iopub.status.idle":"2025-04-29T13:44:05.235907Z","shell.execute_reply.started":"2025-04-29T13:44:05.230947Z","shell.execute_reply":"2025-04-29T13:44:05.234883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Create Data Matrix & Labels**","metadata":{}},{"cell_type":"code","source":"index = 0\n\ndata = np.zeros((400, 10304))\nlabels = np.zeros(400)\n\nfor folder_name in os.listdir(\"/kaggle/input/att-database-of-faces\"):\n    if folder_name == \"README\":\n        continue\n\n    root_path = \"/kaggle/input/att-database-of-faces/\" + folder_name\n    \n    for img in os.listdir(root_path):\n        img = np.asarray(Image.open(root_path +  \"/\" +  img))\n        img = img / 255.0\n        \n        flatten_img = np.ravel(img)\n        data[index] = flatten_img\n        \n        labels[index] = int(folder_name[1:])\n\n        index += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.243538Z","iopub.execute_input":"2025-04-29T13:44:05.243859Z","iopub.status.idle":"2025-04-29T13:44:05.814263Z","shell.execute_reply.started":"2025-04-29T13:44:05.243806Z","shell.execute_reply":"2025-04-29T13:44:05.813393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Split Data Into Train and Test**","metadata":{}},{"cell_type":"code","source":"train_data   = data[::2]\ntrain_labels = labels[::2]\n\ntest_data   = data[1::2]\ntest_labels = labels[1::2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.815727Z","iopub.execute_input":"2025-04-29T13:44:05.816071Z","iopub.status.idle":"2025-04-29T13:44:05.820396Z","shell.execute_reply.started":"2025-04-29T13:44:05.816041Z","shell.execute_reply":"2025-04-29T13:44:05.819738Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Bouns Part**","metadata":{}},{"cell_type":"markdown","source":"## **Define Autoencoder Architecture**","metadata":{}},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n        \n        self.encoder = nn.Sequential(\n            # Block 1: 2 Conv + MaxPool (112x92 → 56x46)\n            nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2),  # 112x92 → 56x46\n        \n            # Block 2: 2 Conv + MaxPool (56x46 → 28x23)\n            nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2),  # 56x46 → 28x23\n        \n            # Block 3: 2 Conv + MaxPool (28x23 → 14x12)\n            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.ZeroPad2d((0, 1, 0, 0)),  # Pad right side of width by 1 (23 → 24)\n            nn.MaxPool2d(kernel_size = 2, stride = 2),  # 28x24 → 14x12\n        \n            # Block 4: 2 Conv + MaxPool (14x12 → 7x6)\n            nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 32, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size = 2, stride = 2),  # 14x12 → 7x6\n        )\n\n        self.decoder = nn.Sequential(\n            # Block 1: 7x6 → 14x12\n            nn.ConvTranspose2d(32, 32, kernel_size = 2, stride = 2),  # 7x6 → 14x12\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n\n            # Block 2: 14x12 → 28x23 (with cropping)\n            nn.ConvTranspose2d(64, 32, kernel_size = 2, stride = 2),  # 14x12 → 28x24\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.ConstantPad2d((0, -1, 0, 0), value = 0),  # Crop right by 1 pixel: 24 → 23\n            nn.Conv2d(32, 32, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n\n            # Block 3: 28x23 → 56x46\n            nn.ConvTranspose2d(32, 16, kernel_size = 2, stride = 2),  # 28x23 → 56x46\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n\n            # Block 4: 56x46 → 112x92 (final upscale)\n            nn.ConvTranspose2d(16, 16, kernel_size = 2, stride = 2),  # 56x46 → 112x92\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.Conv2d(16, 1, kernel_size = 3, stride = 1, padding = 1),\n            nn.Sigmoid(),  # Normalize to [0, 1]\n        )\n\n    def forward(self, x):\n        embedding = self.encoder(x)\n        reconstruct = self.decoder(embedding)\n        return embedding, reconstruct","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.821471Z","iopub.execute_input":"2025-04-29T13:44:05.821776Z","iopub.status.idle":"2025-04-29T13:44:05.841271Z","shell.execute_reply.started":"2025-04-29T13:44:05.821751Z","shell.execute_reply":"2025-04-29T13:44:05.840514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Define Loss, Optimizer, and learning rate Scheduler** ","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = Autoencoder().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.843042Z","iopub.execute_input":"2025-04-29T13:44:05.843287Z","iopub.status.idle":"2025-04-29T13:44:05.875987Z","shell.execute_reply.started":"2025-04-29T13:44:05.843270Z","shell.execute_reply":"2025-04-29T13:44:05.874953Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Create Custom Dataset**","metadata":{}},{"cell_type":"code","source":"class FaceDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = self.data[idx]\n        img.resize((112, 92))\n        \n        if self.transform:\n            img = self.transform(img)\n        else:\n            img = torch.from_numpy(img).float()\n            img = img.unsqueeze(0)\n        return img, img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.877007Z","iopub.execute_input":"2025-04-29T13:44:05.877640Z","iopub.status.idle":"2025-04-29T13:44:05.883293Z","shell.execute_reply.started":"2025-04-29T13:44:05.877613Z","shell.execute_reply":"2025-04-29T13:44:05.882374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Create Dataloaders**","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(p = 0.5),\n    transforms.ColorJitter(brightness = 0.2, contrast = 0.2),\n    transforms.ToTensor(),\n])\n\ntrain_idx, val_idx = train_test_split(np.arange(len(train_data)), test_size = 0.2, random_state = 42)\ntrain_images = train_data[train_idx]\nval_images   = train_data[val_idx]\n\ntrain_dataset = FaceDataset(train_images, transform = train_transform)\nval_dataset   = FaceDataset(val_images)\n\nbatch_size   = 4  # You can adjust this\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\nval_loader   = DataLoader(val_dataset, batch_size   = batch_size, shuffle = False)\n\nmodel = Autoencoder().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 10, factor = 0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.884066Z","iopub.execute_input":"2025-04-29T13:44:05.884323Z","iopub.status.idle":"2025-04-29T13:44:05.915719Z","shell.execute_reply.started":"2025-04-29T13:44:05.884304Z","shell.execute_reply":"2025-04-29T13:44:05.915076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training parameters\nnum_epochs = 300\nbest_val_loss = float('inf')\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    \n    # Batch training loop\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        \n        _, output = model(data)\n        \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * data.size(0)\n    \n    # Validation loop\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for data, target in val_loader:\n            data, target = data.to(device), target.to(device)\n            \n            _, output = model(data)\n            \n            loss = criterion(output, target)\n            \n            val_loss += loss.item() * data.size(0)\n    \n    # Calculate average losses\n    train_loss /= len(train_loader.dataset)\n    val_loss   /= len(val_loader.dataset)\n    \n    # Update learning rate\n    scheduler.step(val_loss)\n    \n    # Print progress\n    if epoch % 5 == 0:\n        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n              f'Train Loss: {train_loss:.4f}, '\n              f'Val Loss: {val_loss:.4f}, '\n              f'LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n    \n    # Save best model\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_autoencoder.pth')\n\n# Save final model\ntorch.save(model.state_dict(), 'final_autoencoder.pth')\nprint('Training complete!')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T13:44:05.916562Z","iopub.execute_input":"2025-04-29T13:44:05.916806Z","iopub.status.idle":"2025-04-29T14:03:30.212101Z","shell.execute_reply.started":"2025-04-29T13:44:05.916788Z","shell.execute_reply":"2025-04-29T14:03:30.211257Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Evaluate Autoencoder on Test Data**","metadata":{}},{"cell_type":"code","source":"checkpoint_path = 'best_autoencoder.pth'\nmodel.load_state_dict(torch.load(checkpoint_path))\n\nmodel.eval()\n\nwith torch.no_grad():\n    total_test_loss = 0\n\n    for index in range(len(test_data)):\n        img = test_data[index]\n        img.resize((112, 92))\n        \n        img = torch.from_numpy(img).float()\n        img = img.unsqueeze(0).unsqueeze(0)\n        img = img\n        \n        img = img.to(device)\n        \n        _, output = model(img)\n\n        loss = criterion(output, img)\n        total_test_loss += loss.item()\n\n    average_test_loss = total_test_loss / len(test_data)\n    print(f'\\nTest Loss: {average_test_loss:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T14:03:30.212978Z","iopub.execute_input":"2025-04-29T14:03:30.213263Z","iopub.status.idle":"2025-04-29T14:03:32.336743Z","shell.execute_reply.started":"2025-04-29T14:03:30.213230Z","shell.execute_reply":"2025-04-29T14:03:32.335747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Display The Reconstructed Image**","metadata":{}},{"cell_type":"code","source":"model.eval()\n\nimg = test_data[100]   \nimg.resize((112, 92))\n\n# Prepare the image\nimg_tensor = torch.from_numpy(img).float()\nimg_tensor = img_tensor.unsqueeze(0).unsqueeze(0).to(device)\nimg_tensor = img_tensor\n\n# Forward pass\nwith torch.no_grad():\n    _, reconstructed = model(img_tensor)\n\n# Convert back to numpy\noriginal_img = img_tensor.squeeze().cpu().numpy()\nreconstructed_img = reconstructed.squeeze().cpu().numpy()\n\n# Plot\nplt.figure(figsize=(6,3))\n\n# Original\nplt.subplot(1,2,1)\nplt.imshow(original_img, cmap='gray')\nplt.title('Original')\nplt.axis('off')\n\n# Reconstructed\nplt.subplot(1,2,2)\nplt.imshow(reconstructed_img, cmap='gray')\nplt.title('Reconstructed')\nplt.axis('off')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T14:38:35.353533Z","iopub.execute_input":"2025-04-29T14:38:35.353894Z","iopub.status.idle":"2025-04-29T14:38:35.530916Z","shell.execute_reply.started":"2025-04-29T14:38:35.353870Z","shell.execute_reply":"2025-04-29T14:38:35.529806Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Extract Embedding Part**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}